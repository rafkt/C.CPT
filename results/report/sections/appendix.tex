\newpage
\appendix


\section{Succinct Data Stuctures} \label{App:SDS}
This kind of structures are high space efficient data structures (introduced by \citeauthor{Jacobson89} \citeyear{Jacobson89}) that support rapid and efficient operations, (look Appendix \ref{App:rank_select}), like \emph{rank} \& \emph{select} \cite{dillabaugh_2007, Jacobson89}. A data structure in order to be considered \emph{succinct}, it should use space that approaches the information-theoretic lower bound of the space that is required to represent the data. One interesting fact is that in contrast with other compressed representations succinct data structures do not sacrifice performance in order to deliver space efficiency when represent and retrieve back any relative data. 
\subsection{Why Succinct Data Structures}
Using \emph{Succinct data structures} can help reducing the space required by a lossless approach and keep most of the data "in memory" (which is stated as a main challenge in Section \ref{losslessVSlossy}). This leaves open room to improve an algorithm's scalability. If we consider that compression methods are mostly based in compression and decompression mechanisms, it is almost clear that much time is spent in compressing and decompressing data. Even though, it would have been achieved a space reduction by using a compression method, the overall performance would not have been any good. Even worse, in a scalable level such an algorithm would take huge amounts of time to complete leaving out an important aspect of the algorithm which is scalability. Also, if we consider prediction tools like backward search on FM-Index \cite{Ferragina} which their complexity to find a search pattern depends only on the times a rank/select were performed, this leads to algorithms which are more scalable with a robust performance time which is in-dependable of the input training set; aspect crucial for an algorithms performance.



\section{Functionality of Rank \& Select}\label{App:rank_select}
Let \(B\) be a sequence of \(n\) items. Then \textbf{rank(c)} and \textbf{select(c)} can be defined as:
\begin{description}
  \item[rank(o)] 
  Counts the number of items which appear in \(B\) from its start to its o-th position \cite{Jacobson89}.
  \item[select(o)]
  Finds the o-th occurrence of an element in \(B\) \cite{Jacobson89}.
\end{description}

The time complexity of rank/select queries depends on the structure where these two operation are built on. For example, it is possible to execute rank/select in constant \(\mathcal{O}(1)\) time for some bit-vectors, like rrr-vectors \cite{Raman}, or another binary rank index \cite{dillabaugh_2007}.

\section{Prediction Tasks} \label{App:predtask}
The adoption of which item is predicted after the context and in \(\langle q_{j+1},q_{j+2},\ldots\rangle\) is only specified by the prediction task.
\begin{description}
  \item[Right next item:] The prediction algorithm gives one prediction for the \(q_{j+1}\) coming after the given context.
  \item[Top $K$ predictions:]  The prediction algorithm gives $K$ alternative predictions for the \(q_{j+1}\) item of the given context.
  \item[Distribution of right next items:]  For each item of the alphabet \(\Sigma\), the prediction task gives the item's probability to be the \(q_{j+1}\)-th item.
  \item[Item in a future window]  For a given value of \(w\), it is predicted an item that appears somewhere among the \(q_{j+1}\)-th, \(q_{j+2}\)-th, \ldots, \(q_{j+w}\)-th items. So, \(w\) mostly behaves as a \emph{window} value where the predicted item could appear. 
\end{description}